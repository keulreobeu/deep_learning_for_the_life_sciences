{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkWJvXi8E0kfHhqR2Xnkgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keulreobeu/deep_learning_for_the_life_sciences/blob/main/%EC%83%9D%EC%84%B1_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생성 모델\n",
        "*   고양이 사진으로 학습을 시켜 새로운 고양이 사진을 생성하는 것처럼 새로운 무언가를 생성하는 모델\n",
        "*   알려진 약물 분자 라이브러리를 학습시켜 후보 물질을 생성\n",
        "*   이론적으론 데이터셋의 확률분포를 학습하고 새로운 샘플을 확률적으로 만들어내는 것\n",
        "*   VAE, GAN 등이 있다\n",
        "\n",
        "# VAE\n",
        "*   Variational Auto-Encoder\n",
        "*   Auto-Encoder(오토인코더)는 출럽값을 입력값과 동일하게 만드는 머린서닝 모델\n",
        "*   오토인코더로 데이터셋을 학습하는 것은 결국 모델의 매개변수를 조절해 출력값을 가능한 입력값과 비슷하게 만드는 작업\n",
        "*   입력값이 그대로 출력값으로 나오는 것을 막기 위해 병목 혀상이 발생하는 구조를 가진다.\n",
        "*   입력값이 1000이면 인코더에서 잠재 공간으로 갈수록 값이 작아지고 디코더를 통해 그 값이 다시 커진다\n",
        "*   이로인해 머신러닝 모델이 더 적은수의 값으로 원래 값을 복원할 수 있는 압축효과를 얻음\n",
        "*   너무 적은 입력값으로 학습을 할 순 없지만 그렇다고 입력값이 전부 필요하지는 않음\n",
        "*   VAE의 구조\n",
        "    *   잠재 공간은 데이터셋의 정보를 압축하여 표현하는 공간\n",
        "    *   잠재 공간의 앞쪽은 인코더 뒷쪽은 디코더라 함\n",
        "    *   인코더는 데이터셋을 가져와 압축된 정보로 변환하는 역할\n",
        "    *   디코더는 압축된 정보를 원래 데이터로 되돌리는 역할\n",
        "    *   디코더는 잠재 공간에서 임의의 백터를 가져와 벡터의 각 구성요소에 대해 임의의 값을 선택해서 통과시켜 새로운 데이터를 생성\n",
        "    *   잠재 공간이 아닌곳에서 벡터를 선택하면 학습 데이터와는 전혀 관련 없어 보이는 출력을 얻게됨\n",
        "    *   오직 인코더에서 생성된 특정 영역의 벡터에 대해서만 학습하는 문제 발생\n",
        "*   VAE의 문제점 해결\n",
        "    *   잠재 영역의 벡터가 특정 분포를 갖도록 손실함수에 새로운 항을 추가\n",
        "    *   추가된 항은 보통 잠재영역이 평균이 0이고 분산이 1인 가우시안 분포를 가짐\n",
        "    *   인코더가 무작위 분포가 아닌 알려진 분포의 벡터를 가지도록 제한하는 것\n",
        "    *   인코더에 입력 데이터를 잠재 공간의 벡터로 변환할때 무작위 노이즈를 추가한다\n",
        "    *   디코더가 노이즈를 가진 데이터를 원본 데이터와 가능한 가깝게 출력하기 위한 학습을 수행하여 벡터의 세부하사항에 너무 민감하지 않게 된다\n",
        "\n",
        "\n",
        "# GAN\n",
        "*   VAE처럼 잠재 공간의 벡터를 데이터로 변환하기 위해 디코더 네트워크를 사용\n",
        "*   GAN은 무작위 벡터 값을 전달해서 예상되는 데이터의 분포와 얼마나 일치하는지로 평가한다.\n",
        "*   생성된 데이터가 훈련 데이터와 얼마나 유사한지 측정하는 송실 함수를 만들고 학습 모델을 최적화 한다.\n",
        "*   이는 매우 복잡한 손실함수를 요구함으로 수동으로 손실 함수를 만들어 내는 대신 데이터에서 손실 함수를 학습하는 방법으로 우회 학습한다.\n",
        "*   GAN의 구조\n",
        "    *   두가지 요소로 구성\n",
        "    *   생성자: 무작위 벡터를 취해 새로운 샘플을 만든다\n",
        "    *   구분자: 생성된 데이터와 실제 학습 데이터를 구별하는 시도를 한다.\n",
        "    *   구분자는 출력값의 샘플의 진위 여부를 확률로서 나타내여 생성자의 솔실 함수로 쓰인다.\n",
        "    *   무작위 벡터 값이 생성자로 들어가 만든 출력값은 다시 구분자의 입력으로 사용\n",
        "    *   생성자의 매개변수는 출력값을 가능한 1에 가깝게 만들고, 구분자의 매개변수는 출력값을 가능한 0에 가깝에 만든다.\n",
        "    *   그러나 동시에 학습 데이터가 구분자에 들어갔을때 출력값이 1이 돼어야 한다.\n",
        "    *   이를 적대적 경쟁이라 한다.\n",
        "    *   구분자는 가짜 데이타와 실제 데이터를 구별하기 위해 끊임없이 학습하고, 생성자는 구분자를 속이기 위해 데이터 생성능력을 계속 개선시킨다.\n",
        "\n",
        "*   GAN은 고품질의 샘플을 생성하는 데 유리\n",
        "*   VAE는 고품질 분포를 생성하는 데 유리\n",
        "*   모든 경우에 해당하지는 않고, 두 모델의 성능은 해결하려는 문제와 학습 모델의 세부적인 내용에 따라 다르다.\n",
        "\n",
        "*   고품질의 분포 -> 데이터의 전체 분포를 넓고 고르게 잘 커버, 한장한장은 GAN에 비해 일반적으로 샘플이 부드럽거나 흐릴 수 있지만 다양성(데이터 유형), 밀도 추정, 확률 보정이 잘 되는 좋은 모델을 만듬\n",
        "*   즉 이상치 탐지, 표현 학습, 잠재공간 조작, 데이터 보강의 공정성이 유리함\n",
        "\n",
        "#   생명과학에 생성 모델 응용\n",
        "*   전혀 새로운 데이터를 생성하여, 신약개발, 단백질 생성에 도움\n",
        "*   복잡한 시스템을 더 정확하게 모델링 가능\n",
        "\n",
        "### 신약 후보 물질 찾기\n",
        "*   기존의 후보물질 찾기는 적합한 후보물질이 만들어질 때까지 화학자들의 무작위 합성을 반복하는 노동집약적 방법\n",
        "*   신약 후보물질을 도출하여 생성하여 더 적은수의 실험으로 좋은 결과를 얻을 수 있음\n",
        "*   또한 생성모델은 기존의 화학자들이 생각하지 못했던 혁신적인 분자 구조를 제안하는 잠재력도 가지고 있다.\n",
        "\n",
        "### 단백질 엔지니어링\n",
        "*   단백질은 복잡한 특성을 갖고 있어 원하는 방향으로 엔지지어링하는 것은 매우 어려운 작업\n",
        "*   하지만 딥러닝을 통해 원하는 방향의 단백질을 조금 더 쉽게 만들 수 있음\n",
        "*   난이도 때문에 저분자 수준의 단백질 엔지니어링에서 고분자 수준의 엔지니어링이 가능할 수 있음\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "# 생성 모델 사용하기\n",
        "\n",
        "##### 구버전 코드\n",
        "\n",
        "```\n",
        "import deepchem as dc\n",
        "\n",
        "# 데이터 로드\n",
        "tasks, datasets, transformers = dc.molnet.load_muv()\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "train_smiles = train_dataset.ids\n",
        "\n",
        "\n",
        "# 모델의 SMILES 문자열 규칙에 대한 내용을 정의\n",
        "# 문자열의 최대 길이, 문자열의 목록\n",
        "tokens = set()\n",
        "\n",
        "for s in train_smiles:\n",
        "  tokens = tokens.union(set(s))\n",
        "\n",
        "tokens = sorted(list(tokens))\n",
        "max_length = max(len(s) for s in train_smiles)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "from deepcham.models.tensorgraph.optimizers import Adam, ExponentialDecay\n",
        "from deepchem.models.tensorgraph.models.seqtoseq import AspuruGuzikAutoEncoder\n",
        "\n",
        "model = AspuruGuzikAutoEncoder(tokens, max_length, model_dir='vae')\n",
        "batches_per_epoch = len(train_smiles)/model.batch_size\n",
        "learning_rate = ExponentialDecay(0.001, 0.95, batches_per_epoch)\n",
        "model.set_optimizer(Adam(learning_rate=learning_rate))\n",
        "\n",
        "# 모델 학습\n",
        "def generate_sequences(epochs):\n",
        "  for i in range(epochs):\n",
        "    for s in train_smiles:\n",
        "      yield (s,s)\n",
        "\n",
        "model.fit_sequences(generate_sequences(50))\n",
        "\n",
        "\n",
        "# 분자 생성\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "\n",
        "predictions = model.predict_from_embeddings(np.random.normal(size=(1000, 196)))\n",
        "molecules = []\n",
        "\n",
        "for p in predictions:\n",
        "    smiles = ''.join(p)\n",
        "    if Chem.MolFromSmiles(smiles) is not None:\n",
        "        molecules.append(smiles)\n",
        "\n",
        "for m in molecules:\n",
        "    print(m)\n",
        "\n",
        "\n",
        "# 결과값 분석\n",
        "\n",
        "# 파이선 리스트 축약을 상요해서 SMILES문자열들을 분자 객체로 변환\n",
        "molecules = [Chem.MolFromSmiles(x) for s in smiles_list]\n",
        "\n",
        "# 원자의 수가 열 개 미만인 경우 상호작용 에너지 불충분\n",
        "# 50개 이상의 경우에는 분자의 용해도가 너무 낮음\n",
        "# 10~50개 사이의 분자들 선택\n",
        "good_mol_list = [\n",
        "    x for x in molecules if x.GetNumAtoms() >= 10 and x.GetNumAtoms() <= 50]\n",
        "\n",
        "\n",
        "# QED 점수 계산\n",
        "qed_list = [QED.qed(x) for x in good_mol_list]\n",
        "final_mol_list =[\n",
        "    (a,b) for a,b in zip(good_mol_list, qed_list) if b >= 0.5]\n",
        "\n",
        "# QED 점수를 시각화\n",
        "MolsToGridImage(\n",
        "    [x[0] for x in final_mol_list],\n",
        "    molsPerRow=3,\n",
        "    useSVG=True,\n",
        "    subImgSize=(250,250),\n",
        "    legends=[f'{x[1]:.2f}' for x in final_mol_list])\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VcIVP_7b6yqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTH9wE1_6jMC"
      },
      "outputs": [],
      "source": [
        "import deepchem as dc\n",
        "\n",
        "# 데이터 로드\n",
        "tasks, datasets, transformers = dc.molnet.load_muv()\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "train_smiles = train_dataset.ids\n",
        "\n",
        "\n",
        "# 모델의 SMILES 문자열 규칙에 대한 내용을 정의\n",
        "# 문자열의 최대 길이, 문자열의 목록\n",
        "tokens = set()\n",
        "\n",
        "for s in train_smiles:\n",
        "  tokens = tokens.union(set(s))\n",
        "\n",
        "tokens = sorted(list(tokens))\n",
        "max_length = max(len(s) for s in train_smiles)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "from deepcham.models.tensorgraph.optimizers import Adam, ExponentialDecay\n",
        "from deepchem.models.tensorgraph.models.seqtoseq import AspuruGuzikAutoEncoder\n",
        "\n",
        "model = AspuruGuzikAutoEncoder(tokens, max_length, model_dir='vae')\n",
        "batches_per_epoch = len(train_smiles)/model.batch_size\n",
        "learning_rate = ExponentialDecay(0.001, 0.95, batches_per_epoch)\n",
        "model.set_optimizer(Adam(learning_rate=learning_rate))\n",
        "\n",
        "# 모델 학습\n",
        "def generate_sequences(epochs):\n",
        "  for i in range(epochs):\n",
        "    for s in train_smiles:\n",
        "      yield (s,s)\n",
        "\n",
        "model.fit_sequences(generate_sequences(50))\n",
        "\n",
        "\n",
        "# 분자 생성\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "\n",
        "predictions = model.predict_from_embeddings(np.random.normal(size=(1000, 196)))\n",
        "molecules = []\n",
        "\n",
        "for p in predictions:\n",
        "    smiles = ''.join(p)\n",
        "    if Chem.MolFromSmiles(smiles) is not None:\n",
        "        molecules.append(smiles)\n",
        "\n",
        "for m in molecules:\n",
        "    print(m)\n",
        "\n",
        "\n",
        "# 결과값 분석\n",
        "\n",
        "# 파이선 리스트 축약을 상요해서 SMILES문자열들을 분자 객체로 변환\n",
        "molecules = [Chem.MolFromSmiles(x) for s in smiles_list]\n",
        "\n",
        "# 원자의 수가 열 개 미만인 경우 상호작용 에너지 불충분\n",
        "# 50개 이상의 경우에는 분자의 용해도가 너무 낮음\n",
        "# 10~50개 사이의 분자들 선택\n",
        "good_mol_list = [\n",
        "    x for x in molecules if x.GetNumAtoms() >= 10 and x.GetNumAtoms() <= 50]\n",
        "\n",
        "\n",
        "# QED 점수 계산\n",
        "qed_list = [QED.qed(x) for x in good_mol_list]\n",
        "final_mol_list =[\n",
        "    (a,b) for a,b in zip(good_mol_list, qed_list) if b >= 0.5]\n",
        "\n",
        "# QED 점수를 시각화\n",
        "MolsToGridImage(\n",
        "    [x[0] for x in final_mol_list],\n",
        "    molsPerRow=3,\n",
        "    useSVG=True,\n",
        "    subImgSize=(250,250),\n",
        "    legends=[f'{x[1]:.2f}' for x in final_mol_list])"
      ]
    }
  ]
}